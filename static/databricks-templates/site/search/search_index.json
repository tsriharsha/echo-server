{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home page","text":""},{"location":"performance/spark-dbsql-template/","title":"Spark DBSQL Query Performance Issue Template","text":""},{"location":"performance/spark-dbsql-template/#spark-dbsql-query-performance-issue-template","title":"Spark DBSQL Query Performance Issue Template","text":"<p>The objective of this template is to help you create a good issue for the Spark DBSQL Query Performance Issue Template.  Please follow the instructions below and delete this text before submitting your issue.</p>"},{"location":"performance/spark-dbsql-template/#things-to-include-but-databricks-solutions-architects-cannot-access","title":"Things to include but Databricks Solutions Architects cannot access","text":"<ol> <li>Databricks Solutions Architects cannot access the following urls if you chose to send (please do so, but we cannot access)<ul> <li>Notebook url</li> <li>Job run url</li> </ul> </li> </ol>"},{"location":"performance/spark-dbsql-template/#spark-job-batch-etl-job-with-workflows","title":"Spark Job (Batch ETL Job with workflows)","text":"<ol> <li>Databricks Runtime Version (Screenshot)</li> <li>Cluster Size and VM Type (Screenshot)</li> <li>Is photon enabled (Screenshot)</li> <li>Spark Settings, please scrub out any keys (Screenshot)</li> <li>Init Scripts, (Screenshot)</li> <li>Are you running any .collect(), .toPandas() or running a lot of counts in the table?</li> <li>Ganglia Metrics (Screenshot)</li> <li>Snippet of the code that is causing the issue (if possible)</li> <li>Snippet of the logs (if possible)</li> <li>Explain plan by running EXPLAIN EXTENDED on the query (if possible)</li> </ol>"},{"location":"performance/spark-dbsql-template/#super-important-spark-ui-screenshots","title":"Super Important: Spark UI Screenshots","text":"<p>You must do this on a separate cluster or a job run otherwise there will be potentially other jobs running and skewing the results</p> <ol> <li>Spark UI Job Page, sort by duration and take a screenshot of the offenders</li> <li>Spark UI Stage Page, and show us if there is any spil to disk at the top</li> <li>Spark UI SQL graph and click expand all details and click the button that says download screen as PNG</li> </ol>"},{"location":"performance/spark-dbsql-template/#super-important-storage-information","title":"Super Important: Storage information","text":"<ol> <li>How many files are in the table (if its delta table you can run <code>DESCRIBE DETAIL &lt;table_name&gt;</code>)</li> <li>What is the query history and operational metrics on the table (if its delta table you can run <code>DESCRIBE HISTORY &lt;table_name&gt;</code>)</li> <li>If it is parquet just try to get the number of files and the size of atleast one file.</li> <li>What is the # of columns in the table</li> </ol>"},{"location":"performance/spark-dbsql-template/#example-email","title":"Example Email:","text":""},{"location":"performance/spark-job-template/","title":"Spark Batch Job","text":""},{"location":"performance/spark-job-template/#spark-job-performance-issue-template","title":"Spark Job Performance Issue Template","text":"<p>The objective of this template is to help you create a good issue for the Spark Job Performance Issue Template.  Please follow the instructions below and delete this text before submitting your issue.</p>"},{"location":"performance/spark-job-template/#things-to-include-but-we-cannot-access","title":"Things to include but we cannot access","text":"<ol> <li>Databricks Solutions Architects cannot access the following urls if you chose to send (please do so, but we cannot access)<ul> <li>Notebook url</li> <li>Job run url</li> </ul> </li> </ol>"},{"location":"performance/spark-job-template/#spark-job-batch-etl-job-with-workflows","title":"Spark Job (Batch ETL Job with workflows)","text":"1. Databricks Runtime Version <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> 2. Cluster Size and VM Type <p></p> 3. Is photon enabled <p></p> 4. Spark Settings <p></p> 5. Init Scripts <p></p> 6. Are you running any .collect(), .toPandas() or running a lot of counts in the table? <p></p> 7. Ganglia Metrics <p>...</p> 8. Snippet of the code that is causing the issue (if possible) <p>...</p> 9. Export of the logs (if possible) <p>...</p> 10. Explain plan by running EXPLAIN EXTENDED on the query (if possible) <p>...</p>"},{"location":"performance/spark-job-template/#super-important-spark-ui-screenshots","title":"Super Important: Spark UI Screenshots","text":"<p>You must do this on a separate cluster or a job run otherwise there will be potentially other jobs running and skewing the results</p> <ol> <li>Spark UI Job Page, sort by duration and take a screenshot of the offenders</li> <li>Spark UI Stage Page, and show us if there is any spil to disk at the top</li> <li>Spark UI SQL graph and click expand all details and click the button that says download screen as PNG</li> </ol> 1. Spark UI Job Page &amp; please sort it by duration and take a screenshot of the offenders <p></p> 2. Spark UI Stage Page, and show us if there is any spill to disk at the top and the amount of shuffle <p></p>"},{"location":"performance/spark-job-template/#super-important-storage-information","title":"Super Important: Storage information","text":"<ol> <li>How many files are in the table (if its delta table you can run <code>DESCRIBE DETAIL &lt;table_name&gt;</code>)</li> <li>What is the query history and operational metrics on the table (if its delta table you can run <code>DESCRIBE HISTORY &lt;table_name&gt;</code>)</li> <li>If it is parquet just try to get the number of files and the size of atleast one file.</li> <li>What is the # of columns in the table</li> </ol>"},{"location":"performance/spark-job-template/#example-email","title":"Example Email:","text":""}]}